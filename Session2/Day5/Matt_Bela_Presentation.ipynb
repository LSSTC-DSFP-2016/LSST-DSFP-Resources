{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forest Classifier\n",
    "***\n",
    "By Matt Hartley and Bela Abolfathi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "* Random forests are grown from decision trees. \n",
    "* A single tree takes an input, and through a series of tests on the attributes of the data it outputs a class. \n",
    "* Built by randomly splitting the data repeatedly and picking the best split.\n",
    "* Decision trees tend to overfit the input and are therefore difficult to generalize. \n",
    "* 100% accuracy only on training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "* An input vector is put through each tree in the forest. \n",
    "* Determines cuts by fitting a number of decision trees on random sub-samples of the data.\n",
    "* Tries to avoid overfitting by averaging or taking the mode of the outputs of each tree.\n",
    "* Better generalization, but not as interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/belaabolfathi/anaconda3/lib/python3.5/site-packages/astroquery/sdss/__init__.py:28: UserWarning: Experimental: SDSS has not yet been refactored to have its API match the rest of astroquery (but it's nearly there).\n",
      "  warnings.warn(\"Experimental: SDSS has not yet been refactored to have its API \"\n",
      "/Users/belaabolfathi/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from astroquery.sdss import SDSS\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Random state\n",
    "seed = 44\n",
    "\n",
    "#Query input data\n",
    "TSquery = \"\"\"SELECT TOP 10000 \n",
    "             p.psfMag_r, p.fiberMag_r, p.fiber2Mag_r, p.petroMag_r, \n",
    "             p.deVMag_r, p.expMag_r, p.modelMag_r, p.cModelMag_r, \n",
    "             s.class\n",
    "             FROM PhotoObjAll AS p JOIN specObjAll s ON s.bestobjid = p.objid\n",
    "             WHERE p.mode = 1 AND s.sciencePrimary = 1 AND p.clean = 1 AND s.class != 'QSO'\n",
    "             ORDER BY p.objid ASC\n",
    "               \"\"\"\n",
    "#Separate features from labels, cast as numpy array\n",
    "SDSSts = SDSS.query_sql(TSquery)\n",
    "SDSSts.convert_bytestring_to_unicode()\n",
    "sdss = SDSSts.to_pandas()\n",
    "data = np.array(sdss.drop('class', axis=1))\n",
    "labels = np.array(sdss['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting of decision tree vs random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 100%\n",
      "Accuracy on test set: 95%\n"
     ]
    }
   ],
   "source": [
    "#Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, \n",
    "                                                    random_state=seed)\n",
    "#Initialize and train decision tree\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate accuracy\n",
    "dtc_train_acc = np.sum(dtc.predict(X_train)==y_train)/len(y_train)\n",
    "dtc_test_acc = np.sum(dtc.predict(X_test)==y_test)/len(y_test)\n",
    "print('Accuracy on training set: {:d}%'.format(int(round((dtc_train_acc*100)))))\n",
    "print('Accuracy on test set: {:d}%'.format(int(round(dtc_test_acc*100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 100%\n",
      "Accuracy on test set: 97%\n"
     ]
    }
   ],
   "source": [
    "#Choose number of trees to train on\n",
    "n_trees = 8\n",
    "\n",
    "#Initialize and train random forest\n",
    "rfc = RandomForestClassifier(n_estimators=n_trees, random_state=seed)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate accuracy\n",
    "rfc_train_acc = np.sum(rfc.predict(X_train)==y_train)/len(y_train)\n",
    "rfc_test_acc = np.sum(rfc.predict(X_test)==y_test)/len(y_test)\n",
    "print('Accuracy on training set: {:d}%'.format(int(round(rfc_train_acc*100))))\n",
    "print('Accuracy on test set: {:d}%'.format(int(round(rfc_test_acc*100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Similar Algorithms\n",
    "\n",
    "##### Extra Trees:\n",
    "* Fits decision trees based on *all* of the input data.\n",
    "* Decision boundaries are chosen at random, rather than choosing the average or mode of the classes.\n",
    "\n",
    "##### Ada Boost:\n",
    "* Boosting is a technique that aims to create a strong classifier from an ensemble of weak classifiers.\n",
    "* Picks weak learners, weights them in favor of instances they misclassified so that subsequent classifiers can improve by focusing on difficult cases.\n",
    "* Sensitive to noisy data and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improved figure\n",
    "\n",
    "![Decision Surfaces](decision_surfaces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Original figure \n",
    "\n",
    "![sklearn](sklearn_rf.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
